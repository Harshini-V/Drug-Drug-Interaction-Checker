{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "This Jupyter notebook covers some of the data processing steps followed to obtain usable data for our visualization and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, data was obtained from DrugBank using a script found: https://gist.github.com/rosherbal/56461421c69a8a7da775336c95fa62e0\n",
    "This was slightly modified to obtain desired data. To run script:\n",
    "\n",
    "python extract_db.py\n",
    "\n",
    "The output has all the drugs, plus synonym, classification, drug interactions, pathways, and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several other intermediary files were used to extract desired data from the output above, but those are uneccesary to include here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Features for ML model\n",
    "The scripts below outline how the features were obtained for the ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract Drug-Target Data\n",
    "def extract_drug_targets(input_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Ensure target columns are lists of strings or empty\n",
    "    def parse_targets(x):\n",
    "        if pd.isna(x) or x == \"[]\":\n",
    "            return []\n",
    "        try:\n",
    "            return list(set(ast.literal_eval(x)))  # Remove duplicates\n",
    "        except (ValueError, SyntaxError):\n",
    "            return [x]\n",
    "\n",
    "    df['target_name'] = df['target_name'].apply(parse_targets)\n",
    "\n",
    "    # Group targets by drug and remove duplicates\n",
    "    drug_targets = (\n",
    "        df.groupby(['dg_name'])['target_name']\n",
    "        .agg(lambda x: list(set(sum(x, []))))  # Flatten lists and remove duplicates\n",
    "        .reset_index()\n",
    "    )\n",
    "    return drug_targets\n",
    "\n",
    "# Step 2: Match Drug Interactions with Targets\n",
    "def get_interaction_targets(interaction_csv, drug_targets):\n",
    "    interactions = pd.read_csv(interaction_csv)\n",
    "\n",
    "    # Lookup for drug-target data\n",
    "    drug_target_map = {\n",
    "        row['dg_name']: set(row['target_name']) for _, row in drug_targets.iterrows()\n",
    "    }\n",
    "\n",
    "    # Match interactions with targets\n",
    "    interaction_targets = []\n",
    "    for _, row in interactions.iterrows():\n",
    "        drug1, drug2 = row['Drug_Name_1'], row['Drug_Name_2']\n",
    "        drug1_targets = drug_target_map.get(drug1, set())\n",
    "        drug2_targets = drug_target_map.get(drug2, set())\n",
    "\n",
    "        interaction_targets.append([drug1, drug2, drug1_targets, drug2_targets])\n",
    "\n",
    "    columns = ['Drug_Name_1', 'Drug_Name_2', 'Drug1_Targets', 'Drug2_Targets']\n",
    "    interaction_df = pd.DataFrame(interaction_targets, columns=columns)\n",
    "    return interaction_df\n",
    "\n",
    "# Step 3: Calculate Jaccard Similarity\n",
    "def calculate_jaccard(interaction_df, output_csv):\n",
    "    jaccard_scores = []\n",
    "    for _, row in interaction_df.iterrows():\n",
    "        try:\n",
    "            targets1 = row['Drug1_Targets']\n",
    "            targets2 = row['Drug2_Targets']\n",
    "            if targets1 and targets2:  # Avoid empty sets\n",
    "                jaccard = len(targets1 & targets2) / len(targets1 | targets2)\n",
    "            else:\n",
    "                jaccard = 0.0 # No similar\n",
    "        except Exception:\n",
    "            jaccard = 0.0  # Skip problematic rows\n",
    "        jaccard_scores.append(jaccard)\n",
    "\n",
    "    # Create final output df\n",
    "    result_df = interaction_df[['Drug_Name_1', 'Drug_Name_2']].copy()\n",
    "    result_df['Jaccard_Similarity'] = jaccard_scores\n",
    "\n",
    "    # Save results\n",
    "    result_df.to_csv(output_csv, index=False)\n",
    "    return result_df\n",
    "\n",
    "# Main workflow\n",
    "input_csv = 'extracted_full.csv'\n",
    "interaction_csv = 'predict_pairs_dwindle.csv'\n",
    "output_similarity_csv = 'jaccard_similarity_ddinter.csv'\n",
    "\n",
    "drug_targets = extract_drug_targets(input_csv)\n",
    "interaction_targets = get_interaction_targets(interaction_csv, drug_targets)\n",
    "similarity_results = calculate_jaccard(interaction_targets, output_similarity_csv)\n",
    "\n",
    "print(\"Jaccard similarity computation complete. Results saved to\", output_similarity_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanimoto Correlation\n",
    "This is calculated in the ML model code. The code below shows how the SMILES data is extracted, which is used for the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SDF file\n",
    "sdf_file = \"structures.sdf\"\n",
    "suppl = Chem.SDMolSupplier(sdf_file)\n",
    "\n",
    "data = [] # Store data\n",
    "\n",
    "# Extract information\n",
    "for mol in suppl:\n",
    "    if mol is not None:\n",
    "        database_id = mol.GetProp('DRUGBANK_ID') if mol.HasProp('DRUGBANK_ID') else \"\"\n",
    "        smiles = Chem.MolToSmiles(mol)\n",
    "        data.append([database_id, smiles])\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df = pd.DataFrame(data, columns=['DRUGBANK_ID', 'SMILES'])\n",
    "df.to_csv(\"SMILES_per_drugID.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAERS Data Extraction\n",
    "This was done using two scripts, get_features_faers.py, and batch_run.py.\n",
    "\n",
    "batch_run.py runs batches of the specified amount (in this case 1000) to call the FAERS API. It calls get_features_faers.py, which is what actually calls and outputs the data, using a subprocess.\n",
    "\n",
    "To run:\n",
    "\n",
    "python batch_run.py\n",
    "\n",
    "The output from this is a file of all the specified drug pairs, each with the counted number of adverse events, and the severity level of those adverse events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Extracted/Calculated Data\n",
    "The code below merges all of the data for feeding to the model. This is an example of a helper script used. This project has many, but we felt including only the most important one was necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "# Get FAERS data\n",
    "df_faers = pd.read_csv(\"faers_feats.csv\", low_memory=False)\n",
    "\n",
    "# Tanimoto calculations\n",
    "tanimoto = pd.read_csv(\"tanimoto_sim_all.csv\", low_memory=False)\n",
    "\n",
    "# Merge these two\n",
    "faers_tan = pd.merge(df_faers, tanimoto,\n",
    "                     on=['Drug_Name_1', 'Drug_Name_2'], how='inner')\n",
    "filt_faers_tan = faers_tan.drop_duplicates()\n",
    "\n",
    "# Get Jaccard Similarities\n",
    "jaccard = pd.read_csv(\"jaccard_similarity.csv\", low_memory=False)\n",
    "\n",
    "# Merge these with all the previous data\n",
    "merged_df = pd.merge(filt_faers_tan, jaccard,\n",
    "                     on=['Drug_Name_1', 'Drug_Name_2'], how='inner')\n",
    "filtered_df = merged_df.drop_duplicates()\n",
    "\n",
    "# Add label for testing/training if desired\n",
    "# This allows metrics to see how model performed\n",
    "# DO NOT USE WHEN RUNNING FINAL DATA - ONLY FOR TEST AND TRAIN\n",
    "def add_label(filtered_df):\n",
    "    df = pd.read_csv(\"data.csv\", low_memory=False)\n",
    "    \n",
    "    # Extract drug names and label only\n",
    "    df_label = df[['Drug_Name_1', 'Drug_Name_2', 'label']]\n",
    "    \n",
    "    # Merge with other data\n",
    "    final_df = pd.merge(filtered_df, df_label,\n",
    "                        on=['Drug_Name_1', 'Drug_Name_2'], how='inner')\n",
    "    return final_df\n",
    "\n",
    "# Save the filtered df - no label\n",
    "filtered_df.to_csv(\"data_with_features.csv\", index=False)\n",
    "\n",
    "# Save the df with label\n",
    "labeled_df = add_label(filtered_df)\n",
    "labeled_df.to_csv(\"data_with_features_and_label.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DVA_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
